{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61ff8f490b224976bd71aa5259209279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64d8a876a574324be296a53ef11d7a3",
              "IPY_MODEL_a191296f2ffc46f6bed95363a48e28c1",
              "IPY_MODEL_5a3ed47808b04dec8c0c3d9862cd3361"
            ],
            "layout": "IPY_MODEL_24545cb3abb2416f9fe6e3b8be059a59"
          }
        },
        "e64d8a876a574324be296a53ef11d7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b24824a2934e6f966937d4c54544a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f500d9a3e85b47be935c4523347f53ab",
            "value": "100%"
          }
        },
        "a191296f2ffc46f6bed95363a48e28c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fcd4733ee9a439c90875a814eb351a8",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd8a5604eaaf4d59849e517b3a09755f",
            "value": 20
          }
        },
        "5a3ed47808b04dec8c0c3d9862cd3361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28af9eeb43744d668533c5e8a9f79eed",
            "placeholder": "​",
            "style": "IPY_MODEL_1374dc365dd14a06ac006f3d9c6a0977",
            "value": " 20/20 [00:44&lt;00:00,  2.10s/it]"
          }
        },
        "24545cb3abb2416f9fe6e3b8be059a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b24824a2934e6f966937d4c54544a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f500d9a3e85b47be935c4523347f53ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fcd4733ee9a439c90875a814eb351a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8a5604eaaf4d59849e517b3a09755f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28af9eeb43744d668533c5e8a9f79eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1374dc365dd14a06ac006f3d9c6a0977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Get the data"
      ],
      "metadata": {
        "id": "SJmeLyP_5-bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIWRmWai0uU0",
        "outputId": "7b93a6ef-78ee-4bea-cc8b-a385849a094c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/_NN_NLP/PyTorch/datasets/shoes.zip . "
      ],
      "metadata": {
        "id": "lRVL9fUK1jEF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip shoes.zip"
      ],
      "metadata": {
        "id": "_kt6cc0E5tb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and train the model"
      ],
      "metadata": {
        "id": "WBuSVF4w6HKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "9o-D--oZ6KpN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data loaders\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "train_data_path = \"train\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path,\n",
        "                                              transform=transforms)\n",
        "\n",
        "val_data_path = \"val\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path,\n",
        "                                            transform=transforms)\n",
        "\n",
        "test_data_path = \"test\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path,\n",
        "                                            transform=transforms)\n",
        "\n",
        "batch_size=64\n",
        "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data_loader  = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader  = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "WZ1cBQOU6QQ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define the network\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(12288, 84) # input layer with the size 64*64*3 (input image)\n",
        "    self.fc2 = nn.Linear(84, 50)\n",
        "    self.fc3 = nn.Linear(50,3) # final layer with 3 units as output (for 3 categories)\n",
        "  \n",
        "  def forward(self, x): # bug was here\n",
        "    x = x.view(-1, 12288) # flatten the input image\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "# initialize the model\n",
        "simplenet = SimpleNet()\n",
        "simplenet.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En85lgR17dtZ",
        "outputId": "a6cd5975-2f09-4f1a-fc5a-41792ad9cd73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n",
              "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(simplenet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "B8-3Lbfy8URJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aZzASgJTIE0T"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    \n",
        "    training_loss = 0.0 # set for the epoch\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    # start training for the given epoch\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for inputs, labels in train_loader: # during each batch\n",
        "      \n",
        "      inputs = inputs.to(device) # move to GPU\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      predictions = model(inputs) # get model predictions for the batch\n",
        "      loss = loss_fn(predictions, labels) # compare model predictions with target labels\n",
        "      \n",
        "      optimizer.zero_grad() # zero the gradient\n",
        "      loss.backward() # compute gradient\n",
        "      optimizer.step() # take an optimization step\n",
        "      \n",
        "      training_loss += loss.item()*inputs.size(0) # accumulating loss over each batch\n",
        "      _, predicted = predictions.max(1)\n",
        "      correct += (predicted == labels).sum() # accumulating TP + TN\n",
        "\n",
        "    # get average training loss for the epoch across all training examples\n",
        "    # by deviding the accumulated loss by the number of all training examples (20k) \n",
        "    training_loss /= len(train_loader.dataset) # len(train_loader) gives number of batches\n",
        "    # calculate training accuracy for all training examples\n",
        "    train_accuracy = correct / len(train_loader.dataset)\n",
        "\n",
        "    # evaluate current model performance once all batches were proccessed\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for inputs, labels in val_loader:\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Deactivate gradients for making a prediction\n",
        "      with torch.no_grad(): # (faster and less memory usage)\n",
        "        predictions = model(inputs)\n",
        "      loss = loss_fn(predictions, labels)\n",
        "      valid_loss += loss.item()*inputs.size(0)\n",
        "        \n",
        "      _, predicted = predictions.max(1)\n",
        "      correct += (predicted == labels).sum()\n",
        "      \n",
        "    # get average validation loss for the epoch across all validation batches\n",
        "    valid_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct / len(val_loader.dataset)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1}, train_loss: {training_loss:.2f},\\\n",
        "          val_loss: {valid_loss:.2f}, val_accuracy = {val_accuracy:.2f},\\\n",
        "          train_accuracy = {train_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Start training...*"
      ],
      "metadata": {
        "id": "TYLVbpes8lZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "61ff8f490b224976bd71aa5259209279",
            "e64d8a876a574324be296a53ef11d7a3",
            "a191296f2ffc46f6bed95363a48e28c1",
            "5a3ed47808b04dec8c0c3d9862cd3361",
            "24545cb3abb2416f9fe6e3b8be059a59",
            "18b24824a2934e6f966937d4c54544a4",
            "f500d9a3e85b47be935c4523347f53ab",
            "5fcd4733ee9a439c90875a814eb351a8",
            "fd8a5604eaaf4d59849e517b3a09755f",
            "28af9eeb43744d668533c5e8a9f79eed",
            "1374dc365dd14a06ac006f3d9c6a0977"
          ]
        },
        "id": "Nfh9AcxQ8WNn",
        "outputId": "f3eb8e09-4e44-4164-e065-f4ec1acc40b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61ff8f490b224976bd71aa5259209279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss: 0.99,          val_loss: 0.37, val_accuracy = 0.87,          train_accuracy = 0.67\n",
            "Epoch: 2, train_loss: 0.32,          val_loss: 0.38, val_accuracy = 0.78,          train_accuracy = 0.87\n",
            "Epoch: 3, train_loss: 0.31,          val_loss: 0.31, val_accuracy = 0.88,          train_accuracy = 0.87\n",
            "Epoch: 4, train_loss: 0.22,          val_loss: 0.42, val_accuracy = 0.78,          train_accuracy = 0.92\n",
            "Epoch: 5, train_loss: 0.23,          val_loss: 0.47, val_accuracy = 0.82,          train_accuracy = 0.91\n",
            "Epoch: 6, train_loss: 0.30,          val_loss: 0.35, val_accuracy = 0.88,          train_accuracy = 0.89\n",
            "Epoch: 7, train_loss: 0.17,          val_loss: 0.29, val_accuracy = 0.86,          train_accuracy = 0.94\n",
            "Epoch: 8, train_loss: 0.16,          val_loss: 0.29, val_accuracy = 0.88,          train_accuracy = 0.94\n",
            "Epoch: 9, train_loss: 0.13,          val_loss: 0.28, val_accuracy = 0.89,          train_accuracy = 0.95\n",
            "Epoch: 10, train_loss: 0.09,          val_loss: 0.33, val_accuracy = 0.89,          train_accuracy = 0.97\n",
            "Epoch: 11, train_loss: 0.13,          val_loss: 0.48, val_accuracy = 0.83,          train_accuracy = 0.96\n",
            "Epoch: 12, train_loss: 0.13,          val_loss: 0.28, val_accuracy = 0.88,          train_accuracy = 0.95\n",
            "Epoch: 13, train_loss: 0.12,          val_loss: 0.49, val_accuracy = 0.87,          train_accuracy = 0.95\n",
            "Epoch: 14, train_loss: 0.09,          val_loss: 0.28, val_accuracy = 0.90,          train_accuracy = 0.97\n",
            "Epoch: 15, train_loss: 0.06,          val_loss: 0.29, val_accuracy = 0.89,          train_accuracy = 0.98\n",
            "Epoch: 16, train_loss: 0.09,          val_loss: 0.42, val_accuracy = 0.87,          train_accuracy = 0.96\n",
            "Epoch: 17, train_loss: 0.06,          val_loss: 0.26, val_accuracy = 0.90,          train_accuracy = 0.98\n",
            "Epoch: 18, train_loss: 0.03,          val_loss: 0.28, val_accuracy = 0.91,          train_accuracy = 0.99\n",
            "Epoch: 19, train_loss: 0.03,          val_loss: 0.27, val_accuracy = 0.90,          train_accuracy = 0.99\n",
            "Epoch: 20, train_loss: 0.03,          val_loss: 0.28, val_accuracy = 0.92,          train_accuracy = 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 20 epochs, we get a validation accuracy of 92 percent and a train accuracy of 99 percent.\n",
        "\n",
        "In a real world scenario, we also would be interested in the final test accuracy to better understand how well our model generalizes to unseen data."
      ],
      "metadata": {
        "id": "1-K8pCF__cx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and saving model weights"
      ],
      "metadata": {
        "id": "eOe4gSvW9kP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is just a small example of how we can perform inference (make predictions) with the trained model:"
      ],
      "metadata": {
        "id": "47-GBadbARQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['boot','sandal', 'shoe']\n",
        "\n",
        "img_boot = Image.open(\"./test/boot/boot (948).jpg\")\n",
        "img_boot = transforms(img_boot).to(device)\n",
        "img_boot = torch.unsqueeze(img_boot, 0)\n",
        "\n",
        "img_sand = Image.open(\"./test/sandal/Sandal (948).jpg\")\n",
        "img_sand = transforms(img_sand).to(device)\n",
        "img_sand = torch.unsqueeze(img_sand, 0)\n",
        "\n",
        "img_shoe = Image.open(\"./test/shoe/Shoe (948).jpg\")\n",
        "img_shoe = transforms(img_shoe).to(device)\n",
        "img_shoe = torch.unsqueeze(img_shoe, 0)\n",
        "\n",
        "# set the model in evaluation mode\n",
        "simplenet.eval()\n",
        "prediction_boot = F.softmax(simplenet(img_boot), dim=1) # don't have to apply softmax first\n",
        "prediction_boot = prediction_boot.argmax()\n",
        "print(f'For a boot image the predicted label is {labels[prediction_boot]}') \n",
        "\n",
        "prediction_sand = F.softmax(simplenet(img_sand), dim=1) # don't have to apply softmax first\n",
        "prediction_sand = prediction_sand.argmax()\n",
        "print(f'For a sandal image the predicted label is {labels[prediction_sand]}')\n",
        "\n",
        "prediction_shoe = F.softmax(simplenet(img_shoe), dim=1) # don't have to apply softmax first\n",
        "prediction_shoe = prediction_shoe.argmax()\n",
        "print(f'For a shoe image the predicted label is {labels[prediction_shoe]}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV4HZSjx9tY7",
        "outputId": "141fc9d5-9434-4e24-f2d6-9a6d22eae871"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a boot image the predicted label is boot\n",
            "For a sandal image the predicted label is sandal\n",
            "For a shoe image the predicted label is shoe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = simplenet.state_dict()\n",
        "print(state_dict)\n",
        "torch.save(state_dict, \"our_model.tar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOmrCrxr07ox",
        "outputId": "778fb039-d72d-409c-d787-1b9f8c9d107e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('fc1.weight', tensor([[-0.0080, -0.0045, -0.0142,  ..., -0.0033, -0.0109, -0.0120],\n",
            "        [-0.0046,  0.0023, -0.0080,  ..., -0.0041,  0.0019, -0.0047],\n",
            "        [-0.0145, -0.0017,  0.0030,  ..., -0.0053, -0.0007, -0.0094],\n",
            "        ...,\n",
            "        [-0.0013, -0.0145, -0.0011,  ...,  0.0022, -0.0083, -0.0127],\n",
            "        [-0.0097,  0.0028, -0.0004,  ..., -0.0005, -0.0044, -0.0049],\n",
            "        [-0.0045, -0.0019, -0.0028,  ..., -0.0003, -0.0003, -0.0068]])), ('fc1.bias', tensor([-1.0054e-02, -1.1883e-02, -1.1046e-02, -1.2674e-03, -4.8217e-03,\n",
            "        -5.3069e-03, -1.0981e-04, -8.8741e-03, -3.7216e-03, -7.8429e-03,\n",
            "        -7.5841e-03, -3.9904e-03,  3.7913e-03, -6.0971e-03, -9.9565e-03,\n",
            "        -7.2464e-03, -1.2169e-02,  4.3320e-03,  2.2250e-03,  1.6391e-03,\n",
            "         6.0848e-03,  1.1146e-04, -7.3152e-04, -4.2451e-03, -8.2341e-03,\n",
            "        -2.9684e-03, -3.4728e-03, -7.9106e-03,  7.3752e-03, -1.0087e-02,\n",
            "        -8.2248e-04,  1.4836e-04,  1.2967e-04, -9.3464e-03,  2.7484e-04,\n",
            "        -7.6513e-03, -7.2135e-03, -1.1369e-02, -8.1898e-03, -1.2070e-03,\n",
            "         1.3912e-04, -6.9509e-03, -3.3345e-03, -4.3252e-03, -1.4918e-02,\n",
            "        -9.8074e-03, -7.2990e-03,  7.3073e-03,  2.9278e-03, -7.0618e-03,\n",
            "        -1.1832e-02,  1.4864e-03, -2.2163e-03, -9.0782e-03,  2.0131e-04,\n",
            "        -9.9505e-03, -2.9269e-04, -4.6475e-03, -4.1663e-03,  3.6187e-03,\n",
            "         2.6299e-03,  1.3261e-03, -5.9852e-03,  1.5961e-02, -9.5964e-04,\n",
            "         2.0009e-03, -1.1830e-02, -1.1644e-02, -1.2835e-02, -1.2561e-02,\n",
            "        -1.4540e-02, -4.5485e-03, -2.0451e-03, -1.7746e-04,  1.3555e-03,\n",
            "        -3.4663e-03, -8.7005e-05, -1.2293e-02, -4.9381e-03,  4.2502e-03,\n",
            "        -5.7934e-03, -1.3053e-02,  9.4143e-04, -1.3160e-02])), ('fc2.weight', tensor([[ 0.0891, -0.0364,  0.0607,  ...,  0.0155, -0.1130,  0.0789],\n",
            "        [-0.0476, -0.0838,  0.0789,  ..., -0.0318,  0.0415, -0.0959],\n",
            "        [ 0.0640, -0.0362,  0.0596,  ...,  0.0711,  0.0301,  0.0663],\n",
            "        ...,\n",
            "        [ 0.0914,  0.0619, -0.0026,  ...,  0.0130,  0.0812, -0.0951],\n",
            "        [ 0.0924,  0.0659, -0.0772,  ...,  0.1023,  0.0634,  0.0388],\n",
            "        [-0.1034,  0.0434,  0.0163,  ...,  0.0701,  0.0444,  0.0815]])), ('fc2.bias', tensor([ 0.1023,  0.0361,  0.0981,  0.0844, -0.0006, -0.0159,  0.0514,  0.0192,\n",
            "        -0.0589, -0.0020,  0.0128,  0.0501, -0.0578,  0.0746,  0.0595, -0.0729,\n",
            "        -0.0104,  0.0483, -0.1017,  0.0193, -0.0173, -0.0894, -0.0168, -0.0780,\n",
            "        -0.0547,  0.0204,  0.0707, -0.0078, -0.0925,  0.0184, -0.0414,  0.0823,\n",
            "        -0.0710,  0.0512,  0.0386, -0.0402,  0.0715, -0.0435, -0.0220,  0.0402,\n",
            "         0.0840, -0.1007, -0.0355,  0.0549, -0.0603,  0.0746,  0.0111, -0.1004,\n",
            "         0.0912, -0.0186])), ('fc3.weight', tensor([[ 0.0447, -0.0834, -0.0764,  0.1273,  0.1054,  0.0446,  0.0392,  0.0614,\n",
            "          0.0222,  0.0388,  0.1425,  0.1261,  0.0906,  0.0380, -0.1439,  0.0872,\n",
            "          0.0321, -0.0777,  0.0339,  0.0813,  0.0595,  0.0858,  0.1111, -0.0529,\n",
            "         -0.0866, -0.1297,  0.0435, -0.0390, -0.1276,  0.1258,  0.0723, -0.0091,\n",
            "         -0.0321,  0.0126,  0.1217,  0.0668,  0.1254, -0.1378,  0.1381, -0.0848,\n",
            "         -0.1143,  0.0223,  0.1195,  0.1371, -0.0068, -0.1229, -0.0456, -0.0291,\n",
            "         -0.0162,  0.0606],\n",
            "        [-0.1148,  0.0433,  0.1004,  0.1122,  0.0192,  0.0614, -0.0472,  0.0774,\n",
            "          0.0979,  0.0412, -0.1118, -0.0348, -0.0483, -0.0885, -0.0420, -0.0151,\n",
            "         -0.0515,  0.0956, -0.0479,  0.0586,  0.0792,  0.0382, -0.0372,  0.0906,\n",
            "          0.1221, -0.0758,  0.0965, -0.0162,  0.1220, -0.0625,  0.1078, -0.0904,\n",
            "         -0.0329,  0.1005,  0.0136,  0.0705, -0.0540, -0.0216,  0.0385, -0.0489,\n",
            "         -0.1193, -0.0043, -0.1611,  0.1266,  0.0823,  0.0348,  0.1131, -0.0818,\n",
            "         -0.0475, -0.1267],\n",
            "        [ 0.1331,  0.1307,  0.0347, -0.0830, -0.0265,  0.0108, -0.1167, -0.0349,\n",
            "         -0.1340,  0.0640, -0.0967,  0.1038,  0.0710, -0.0435,  0.0782, -0.0310,\n",
            "         -0.0599, -0.0164,  0.1042, -0.0087,  0.0609, -0.1475, -0.1086,  0.0306,\n",
            "          0.0007, -0.0490,  0.0217,  0.0952, -0.0402, -0.0100,  0.0923,  0.1264,\n",
            "         -0.0271, -0.0696, -0.1255, -0.0402, -0.0600,  0.0241,  0.0796,  0.0549,\n",
            "          0.0956,  0.0012,  0.0142, -0.1257,  0.0245,  0.0060, -0.0177, -0.1381,\n",
            "         -0.1402, -0.1339]])), ('fc3.bias', tensor([-0.0638, -0.0852, -0.0916]))])\n"
          ]
        }
      ]
    }
  ]
}